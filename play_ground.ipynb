{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Source language Vocabulary ...\n",
      "Building Target language Vocabulary ...\n",
      "Finished.\n",
      "Vocabulary sizes:\n",
      "Source:  28\n",
      "Target:  19\n",
      "train_dataset: 16 val_dataset: 2 test_dataset: 2\n"
     ]
    }
   ],
   "source": [
    "# test preprocessing.py\n",
    "from data_processing.preprocessing import TextDataProcessor\n",
    "from data_processing.Dataloader import DataReader\n",
    "\n",
    "data_reader = DataReader('data/fr-en_fr.txt', 'data/fr-en_en.txt')\n",
    "text_data_processor = TextDataProcessor.from_DataReader(data_reader)\n",
    "vocab_src, vocab_tgt =  text_data_processor.build_vocab(src_lang=\"fr\", tgt_lang=\"en\", min_freq=5, random_state=42)\n",
    "train_dataset, val_dataset, test_dataset = text_data_processor.get_dataset()\n",
    "print(f\"train_dataset: {len(train_dataset)} val_dataset: {len(val_dataset)} test_dataset: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128]) torch.Size([16, 128])\n"
     ]
    }
   ],
   "source": [
    "# test Dataloader.py\n",
    "from data_processing.Dataloader import create_dataloaders\n",
    "\n",
    "# data_reader = DataReader('data/fr-en_fr.txt', 'data/fr-en_en.txt')\n",
    "# text_data_processor = TextDataProcessor.from_DataReader(data_reader)\n",
    "train_loader, val_loader = create_dataloaders(text_data_processor, device=torch.device(\"cuda\"), src_lang=\"fr\", tgt_lang=\"en\")\n",
    "for src, tgt in train_loader:\n",
    "    print(src.shape, tgt.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
    "        torch.uint8\n",
    "    )\n",
    "    return subsequent_mask == 0\n",
    "\n",
    "class Batch:\n",
    "    '''\n",
    "    Object for holding a batch of data with mask during training. \n",
    "    params:\n",
    "        src: torch.tensor, source data from a batch interated from DataLoader\n",
    "        tgt: torch.tensor, target data from a batch interated from DataLoader\n",
    "    '''\n",
    "\n",
    "    def __init__(self, src, tgt=None, pad=2):  # 2 = <blank>\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)   # example [16, 128]  -> [16, 1, 128]\n",
    "        if tgt is not None:\n",
    "            self.tgt = tgt[:, :-1]\n",
    "            self.tgt_y = tgt[:, 1:]\n",
    "            self.tgt_mask = self.make_std_mask(self.tgt, pad)\n",
    "            self.ntokens = (self.tgt_y != pad).data.sum()\n",
    "\n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        '''\n",
    "        Create a mask to hide padding and future words.\n",
    "        '''\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)  # example tgt_mask.shape = [16, 1, 127]  [B, 1, max_padding-1]\n",
    "        tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(\n",
    "            tgt_mask.data\n",
    "        )\n",
    "        return tgt_mask  # example [16, 127, 127]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = vocab_tgt[\"<blank>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128]) torch.Size([16, 127])\n"
     ]
    }
   ],
   "source": [
    "data_iter = (Batch(b[0], b[1], pad_idx) for b in train_loader)\n",
    "\n",
    "for i, batch in enumerate(data_iter):\n",
    "    print(batch.src.shape, batch.tgt.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_DL2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
